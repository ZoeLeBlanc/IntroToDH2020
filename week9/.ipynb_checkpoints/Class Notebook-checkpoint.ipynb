{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m', 'Male', 'fem.', 'FemalE', 'Femle']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"m Male fem. FemalE Femle\"\n",
    "text = text.split(' ')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'gender': text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FemalE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Femle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender\n",
       "0       m\n",
       "1    Male\n",
       "2    fem.\n",
       "3  FemalE\n",
       "4   Femle"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      male\n",
       "1       NaN\n",
       "2    female\n",
       "3       NaN\n",
       "4       NaN\n",
       "Name: gender, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].map({'m': 'male', 'fem.': 'female'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: gender, dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].str.match(r\"m\", flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gender[df['gender'].str.match(r\"m\", flags=re.IGNORECASE)] = 'male'\n",
    "df.gender[df['gender'].str.match(r\"f\", flags=re.IGNORECASE)] = 'female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender\n",
       "0    male\n",
       "1    male\n",
       "2  female\n",
       "3  female\n",
       "4  female"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gender = df.gender.str.lower()\n",
    "df.gender[df.gender.str.contains('fem')] = 'female'\n",
    "df.gender[df.gender.str.contains('fem') == False] = 'male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender\n",
       "0    male\n",
       "1    male\n",
       "2  female\n",
       "3  female\n",
       "4  female"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import FreqDist\n",
    "\n",
    "text = \"Queen, one. Cities and after packed to destined design sighed. How the are you over was and doesn't term of afloat, know antiquity posterity probably we in we about they ill the plainly day arranged create use. Answer empty her good is scarfs, it him examples, the would the trial. Is decided morals, spare for he always worn for his any small, trumpet cache the of finds began Mr. I same was the this a sleepiness pros subdued at he and joke. Chance incurred very its world rung the brief. Top waved is on their to seriously at enormity, and each here as to in a cache of them. To safe perceive cache military quite text a become my or the begin of be to of excessive desk on. Is multi was on feedback would influenced used opinion, posts, best rather, get partially the and for any walls rational his\"\n",
    "df = pd.DataFrame({'text': text} , index=[0])\n",
    "df\n",
    "df['tokens'] = df.text.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Queen', ',', 'one', '.', 'Cities', 'and', 'after', 'packed', 'to', 'destined', 'design', 'sighed', '.', 'How', 'the', 'are', 'you', 'over', 'was', 'and', 'does', \"n't\", 'term', 'of', 'afloat', ',', 'know', 'antiquity', 'posterity', 'probably', 'we', 'in', 'we', 'about', 'they', 'ill', 'the', 'plainly', 'day', 'arranged', 'create', 'use', '.', 'Answer', 'empty', 'her', 'good', 'is', 'scarfs', ',', 'it', 'him', 'examples', ',', 'the', 'would', 'the', 'trial', '.', 'Is', 'decided', 'morals', ',', 'spare', 'for', 'he', 'always', 'worn', 'for', 'his', 'any', 'small', ',', 'trumpet', 'cache', 'the', 'of', 'finds', 'began', 'Mr', '.', 'I', 'same', 'was', 'the', 'this', 'a', 'sleepiness', 'pros', 'subdued', 'at', 'he', 'and', 'joke', '.', 'Chance', 'incurred', 'very', 'its', 'world', 'rung', 'the', 'brief', '.', 'Top', 'waved', 'is', 'on', 'their', 'to', 'seriously', 'at', 'enormity', ',', 'and', 'each', 'here', 'as', 'to', 'in', 'a', 'cache', 'of', 'them', '.', 'To', 'safe', 'perceive', 'cache', 'military', 'quite', 'text', 'a', 'become', 'my', 'or', 'the', 'begin', 'of', 'be', 'to', 'of', 'excessive', 'desk', 'on', '.', 'Is', 'multi', 'was', 'on', 'feedback', 'would', 'influenced', 'used', 'opinion', ',', 'posts', ',', 'best', 'rather', ',', 'get', 'partially', 'the', 'and', 'for', 'any', 'walls', 'rational', 'his'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tokens.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = FreqDist(sum(df.tokens, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 10, '.': 9, 'the': 9, 'and': 5, 'of': 5, 'to': 4, 'was': 3, 'for': 3, 'cache': 3, 'a': 3, ...})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Mellower into how and experience its continues essential tones, rain a expect, one to that talk its him of this, linux hesitated profitable noise if the than target, couple made ambushed the better failures different best we reported of fie trust conflict- him but do pouring only room be back. Of without economics the at her bed. Over the and is ports, two crap visuals own gave need can moment. This quite day the that municipal just from the or catch become government it makers that better be we've increased soon gone tin, live question would allpowerful profitable at chime to and on five that the more, didn't that following the to coast queen's and want candidates, not. Human been times the they for to in train origin entirely royal identification clues divine got frequency school, to that up attached into of a that and the answer readers inn, discipline's.\"\n",
    "df2 = pd.DataFrame({'text': text}, index=[0])\n",
    "large_df = df.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df['tokens'] = large_df.text.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen, one. Cities and after packed to destine...</td>\n",
       "      <td>[Queen, ,, one, ., Cities, and, after, packed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mellower into how and experience its continues...</td>\n",
       "      <td>[Mellower, into, how, and, experience, its, co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Queen, one. Cities and after packed to destine...   \n",
       "0  Mellower into how and experience its continues...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [Queen, ,, one, ., Cities, and, after, packed,...  \n",
       "0  [Mellower, into, how, and, experience, its, co...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 text      Queen, one. Cities and after packed to destine...\n",
      "tokens    [Queen, ,, one, ., Cities, and, after, packed,...\n",
      "Name: 0, dtype: object\n",
      "['Queen', ',', 'one', '.', 'Cities', 'and', 'after', 'packed', 'to', 'destined', 'design', 'sighed', '.', 'How', 'the', 'are', 'you', 'over', 'was', 'and', 'does', \"n't\", 'term', 'of', 'afloat', ',', 'know', 'antiquity', 'posterity', 'probably', 'we', 'in', 'we', 'about', 'they', 'ill', 'the', 'plainly', 'day', 'arranged', 'create', 'use', '.', 'Answer', 'empty', 'her', 'good', 'is', 'scarfs', ',', 'it', 'him', 'examples', ',', 'the', 'would', 'the', 'trial', '.', 'Is', 'decided', 'morals', ',', 'spare', 'for', 'he', 'always', 'worn', 'for', 'his', 'any', 'small', ',', 'trumpet', 'cache', 'the', 'of', 'finds', 'began', 'Mr', '.', 'I', 'same', 'was', 'the', 'this', 'a', 'sleepiness', 'pros', 'subdued', 'at', 'he', 'and', 'joke', '.', 'Chance', 'incurred', 'very', 'its', 'world', 'rung', 'the', 'brief', '.', 'Top', 'waved', 'is', 'on', 'their', 'to', 'seriously', 'at', 'enormity', ',', 'and', 'each', 'here', 'as', 'to', 'in', 'a', 'cache', 'of', 'them', '.', 'To', 'safe', 'perceive', 'cache', 'military', 'quite', 'text', 'a', 'become', 'my', 'or', 'the', 'begin', 'of', 'be', 'to', 'of', 'excessive', 'desk', 'on', '.', 'Is', 'multi', 'was', 'on', 'feedback', 'would', 'influenced', 'used', 'opinion', ',', 'posts', ',', 'best', 'rather', ',', 'get', 'partially', 'the', 'and', 'for', 'any', 'walls', 'rational', 'his']\n",
      "0 text      Mellower into how and experience its continues...\n",
      "tokens    [Mellower, into, how, and, experience, its, co...\n",
      "Name: 0, dtype: object\n",
      "['Mellower', 'into', 'how', 'and', 'experience', 'its', 'continues', 'essential', 'tones', ',', 'rain', 'a', 'expect', ',', 'one', 'to', 'that', 'talk', 'its', 'him', 'of', 'this', ',', 'linux', 'hesitated', 'profitable', 'noise', 'if', 'the', 'than', 'target', ',', 'couple', 'made', 'ambushed', 'the', 'better', 'failures', 'different', 'best', 'we', 'reported', 'of', 'fie', 'trust', 'conflict-', 'him', 'but', 'do', 'pouring', 'only', 'room', 'be', 'back', '.', 'Of', 'without', 'economics', 'the', 'at', 'her', 'bed', '.', 'Over', 'the', 'and', 'is', 'ports', ',', 'two', 'crap', 'visuals', 'own', 'gave', 'need', 'can', 'moment', '.', 'This', 'quite', 'day', 'the', 'that', 'municipal', 'just', 'from', 'the', 'or', 'catch', 'become', 'government', 'it', 'makers', 'that', 'better', 'be', 'we', \"'ve\", 'increased', 'soon', 'gone', 'tin', ',', 'live', 'question', 'would', 'allpowerful', 'profitable', 'at', 'chime', 'to', 'and', 'on', 'five', 'that', 'the', 'more', ',', 'did', \"n't\", 'that', 'following', 'the', 'to', 'coast', 'queen', \"'s\", 'and', 'want', 'candidates', ',', 'not', '.', 'Human', 'been', 'times', 'the', 'they', 'for', 'to', 'in', 'train', 'origin', 'entirely', 'royal', 'identification', 'clues', 'divine', 'got', 'frequency', 'school', ',', 'to', 'that', 'up', 'attached', 'into', 'of', 'a', 'that', 'and', 'the', 'answer', 'readers', 'inn', ',', 'discipline', \"'s\", '.']\n"
     ]
    }
   ],
   "source": [
    "for index, row in large_df.iterrows():\n",
    "    print(index, row)\n",
    "    print(word_tokenize(row.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download(\"stopwords\") # You only need to run this once in your script or notebook and then it will exist in your virtual environment\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(row):\n",
    "    tokens = word_tokenize(row)\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        token_lower = token.lower()\n",
    "        if ( token_lower not in string.punctuation) and (token_lower not in stopwords.words('english')):\n",
    "            cleaned_tokens.append(token_lower)\n",
    "#     print(cleaned_tokens)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df['cleaned_tokens'] = large_df.text.apply(custom_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen, one. Cities and after packed to destine...</td>\n",
       "      <td>[Queen, ,, one, ., Cities, and, after, packed,...</td>\n",
       "      <td>[queen, one, cities, packed, destined, design,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mellower into how and experience its continues...</td>\n",
       "      <td>[Mellower, into, how, and, experience, its, co...</td>\n",
       "      <td>[mellower, experience, continues, essential, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Queen, one. Cities and after packed to destine...   \n",
       "0  Mellower into how and experience its continues...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Queen, ,, one, ., Cities, and, after, packed,...   \n",
       "0  [Mellower, into, how, and, experience, its, co...   \n",
       "\n",
       "                                      cleaned_tokens  \n",
       "0  [queen, one, cities, packed, destined, design,...  \n",
       "0  [mellower, experience, continues, essential, t...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Queen, one.', 'Cities and after packed to destined design sighed.', \"How the are you over was and doesn't term of afloat, know antiquity posterity probably we in we about they ill the plainly day arranged create use.\", 'Answer empty her good is scarfs, it him examples, the would the trial.', 'Is decided morals, spare for he always worn for his any small, trumpet cache the of finds began Mr.', 'I same was the this a sleepiness pros subdued at he and joke.', 'Chance incurred very its world rung the brief.', 'Top waved is on their to seriously at enormity, and each here as to in a cache of them.', 'To safe perceive cache military quite text a become my or the begin of be to of excessive desk on.', 'Is multi was on feedback would influenced used opinion, posts, best rather, get partially the and for any walls rational his']\n",
      "['Mellower into how and experience its continues essential tones, rain a expect, one to that talk its him of this, linux hesitated profitable noise if the than target, couple made ambushed the better failures different best we reported of fie trust conflict- him but do pouring only room be back.', 'Of without economics the at her bed.', 'Over the and is ports, two crap visuals own gave need can moment.', \"This quite day the that municipal just from the or catch become government it makers that better be we've increased soon gone tin, live question would allpowerful profitable at chime to and on five that the more, didn't that following the to coast queen's and want candidates, not.\", \"Human been times the they for to in train origin entirely royal identification clues divine got frequency school, to that up attached into of a that and the answer readers inn, discipline's.\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "0    None\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_sentence_tokenizer(row):\n",
    "    tokens = nltk.sent_tokenize(row)\n",
    "    print(tokens)\n",
    "\n",
    "large_df.text.apply(custom_sentence_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              term     score\n",
      "0            cache  0.245302\n",
      "1            would  0.116356\n",
      "2           afloat  0.081767\n",
      "3   multi feedback  0.081767\n",
      "4       one cities  0.081767\n",
      "5          opinion  0.081767\n",
      "6    opinion posts  0.081767\n",
      "7           packed  0.081767\n",
      "8  packed destined  0.081767\n",
      "9        partially  0.081767\n",
      "                term     score\n",
      "0         profitable  0.158585\n",
      "1             better  0.158585\n",
      "2               live  0.079293\n",
      "3  government makers  0.079293\n",
      "4         talk linux  0.079293\n",
      "5               gone  0.079293\n",
      "6           gone tin  0.079293\n",
      "7               talk  0.079293\n",
      "8                got  0.079293\n",
      "9      got frequency  0.079293\n"
     ]
    }
   ],
   "source": [
    "# Join tokens into a string to create a new column with our cleaned text\n",
    "def join_tokens(row):\n",
    "    text = \" \".join(row)\n",
    "    return text\n",
    "\n",
    "large_df['cleaned_text'] = large_df.cleaned_tokens.apply(join_tokens)\n",
    "\n",
    "# Get the text into list for TF-IDF\n",
    "all_docs = large_df.cleaned_text.tolist()\n",
    "\n",
    "# Specify the ngram_range for the Vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "transformed_documents = vectorizer.fit_transform(all_docs)\n",
    "\n",
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "\n",
    "# Output the top tokens for each document\n",
    "for counter, doc in enumerate(transformed_documents_as_array):\n",
    "    # construct a dataframe\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names(), doc))\n",
    "    one_doc_as_df = pd.DataFrame.from_records(tf_idf_tuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "    print(one_doc_as_df[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"queen one cities packed destined design sighed n't term afloat know antiquity posterity probably ill plainly day arranged create use answer empty good scarfs examples would trial decided morals spare always worn small trumpet cache finds began mr sleepiness pros subdued joke chance incurred world rung brief top waved seriously enormity cache safe perceive cache military quite text become begin excessive desk multi feedback would influenced used opinion posts best rather get partially walls rational\",\n",
       " \"mellower experience continues essential tones rain expect one talk linux hesitated profitable noise target couple made ambushed better failures different best reported fie trust conflict- pouring room back without economics bed ports two crap visuals gave need moment quite day municipal catch become government makers better 've increased soon gone tin live question would allpowerful profitable chime five n't following coast queen 's want candidates human times train origin entirely royal identification clues divine got frequency school attached answer readers inn discipline 's\"]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_df.cleaned_text.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  term     score\n",
      "0          afloat know  0.117041\n",
      "1            queen one  0.117041\n",
      "2         probably ill  0.117041\n",
      "3           posts best  0.117041\n",
      "4   posterity probably  0.117041\n",
      "5          plainly day  0.117041\n",
      "6       perceive cache  0.117041\n",
      "7      partially walls  0.117041\n",
      "8      packed destined  0.117041\n",
      "9        opinion posts  0.117041\n",
      "10          one cities  0.117041\n",
      "11      multi feedback  0.117041\n",
      "12       mr sleepiness  0.117041\n",
      "13        morals spare  0.117041\n",
      "14      military quite  0.117041\n",
      "15      know antiquity  0.117041\n",
      "16         joke chance  0.117041\n",
      "17     influenced used  0.117041\n",
      "18      incurred world  0.117041\n",
      "19         ill plainly  0.117041\n",
      "                    term     score\n",
      "0          live question  0.112509\n",
      "1         entirely royal  0.112509\n",
      "2        school attached  0.112509\n",
      "3         inn discipline  0.112509\n",
      "4         increased soon  0.112509\n",
      "5   identification clues  0.112509\n",
      "6            human times  0.112509\n",
      "7   hesitated profitable  0.112509\n",
      "8      government makers  0.112509\n",
      "9          got frequency  0.112509\n",
      "10             soon gone  0.112509\n",
      "11              gone tin  0.112509\n",
      "12             gave need  0.112509\n",
      "13      frequency school  0.112509\n",
      "14       following coast  0.112509\n",
      "15        five following  0.112509\n",
      "16             fie trust  0.112509\n",
      "17            talk linux  0.112509\n",
      "18    failures different  0.112509\n",
      "19            expect one  0.112509\n"
     ]
    }
   ],
   "source": [
    "# Specify the ngram_range for the Vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "transformed_documents = vectorizer.fit_transform(all_docs)\n",
    "\n",
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "\n",
    "# Output the top tokens for each document\n",
    "for counter, doc in enumerate(transformed_documents_as_array):\n",
    "    # construct a dataframe\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names(), doc))\n",
    "    one_doc_as_df = pd.DataFrame.from_records(tf_idf_tuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "    print(one_doc_as_df[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "stemmed = porter.stem(text)\n",
    "print(stemmed == text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(row):\n",
    "    stemmed_words = ''\n",
    "    for token in row.split(' '):\n",
    "#         print(porter.stem(token))\n",
    "        stemmed_words += porter.stem(token) + ' '\n",
    "    return stemmed_words\n",
    "large_df['stemmed_text'] = large_df.cleaned_text.apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queen,\n",
      "one.\n",
      "Cities\n",
      "and\n",
      "after\n",
      "packed\n",
      "to\n",
      "destined\n",
      "design\n",
      "sighed.\n",
      "How\n",
      "the\n",
      "are\n",
      "you\n",
      "over\n",
      "wa\n",
      "and\n",
      "doesn't\n",
      "term\n",
      "of\n",
      "afloat,\n",
      "know\n",
      "antiquity\n",
      "posterity\n",
      "probably\n",
      "we\n",
      "in\n",
      "we\n",
      "about\n",
      "they\n",
      "ill\n",
      "the\n",
      "plainly\n",
      "day\n",
      "arranged\n",
      "create\n",
      "use.\n",
      "Answer\n",
      "empty\n",
      "her\n",
      "good\n",
      "is\n",
      "scarfs,\n",
      "it\n",
      "him\n",
      "examples,\n",
      "the\n",
      "would\n",
      "the\n",
      "trial.\n",
      "Is\n",
      "decided\n",
      "morals,\n",
      "spare\n",
      "for\n",
      "he\n",
      "always\n",
      "worn\n",
      "for\n",
      "his\n",
      "any\n",
      "small,\n",
      "trumpet\n",
      "cache\n",
      "the\n",
      "of\n",
      "find\n",
      "began\n",
      "Mr.\n",
      "I\n",
      "same\n",
      "wa\n",
      "the\n",
      "this\n",
      "a\n",
      "sleepiness\n",
      "pro\n",
      "subdued\n",
      "at\n",
      "he\n",
      "and\n",
      "joke.\n",
      "Chance\n",
      "incurred\n",
      "very\n",
      "it\n",
      "world\n",
      "rung\n",
      "the\n",
      "brief.\n",
      "Top\n",
      "waved\n",
      "is\n",
      "on\n",
      "their\n",
      "to\n",
      "seriously\n",
      "at\n",
      "enormity,\n",
      "and\n",
      "each\n",
      "here\n",
      "a\n",
      "to\n",
      "in\n",
      "a\n",
      "cache\n",
      "of\n",
      "them.\n",
      "To\n",
      "safe\n",
      "perceive\n",
      "cache\n",
      "military\n",
      "quite\n",
      "text\n",
      "a\n",
      "become\n",
      "my\n",
      "or\n",
      "the\n",
      "begin\n",
      "of\n",
      "be\n",
      "to\n",
      "of\n",
      "excessive\n",
      "desk\n",
      "on.\n",
      "Is\n",
      "multi\n",
      "wa\n",
      "on\n",
      "feedback\n",
      "would\n",
      "influenced\n",
      "used\n",
      "opinion,\n",
      "posts,\n",
      "best\n",
      "rather,\n",
      "get\n",
      "partially\n",
      "the\n",
      "and\n",
      "for\n",
      "any\n",
      "wall\n",
      "rational\n",
      "his\n",
      "Mellower\n",
      "into\n",
      "how\n",
      "and\n",
      "experience\n",
      "it\n",
      "continues\n",
      "essential\n",
      "tones,\n",
      "rain\n",
      "a\n",
      "expect,\n",
      "one\n",
      "to\n",
      "that\n",
      "talk\n",
      "it\n",
      "him\n",
      "of\n",
      "this,\n",
      "linux\n",
      "hesitated\n",
      "profitable\n",
      "noise\n",
      "if\n",
      "the\n",
      "than\n",
      "target,\n",
      "couple\n",
      "made\n",
      "ambushed\n",
      "the\n",
      "better\n",
      "failure\n",
      "different\n",
      "best\n",
      "we\n",
      "reported\n",
      "of\n",
      "fie\n",
      "trust\n",
      "conflict-\n",
      "him\n",
      "but\n",
      "do\n",
      "pouring\n",
      "only\n",
      "room\n",
      "be\n",
      "back.\n",
      "Of\n",
      "without\n",
      "economics\n",
      "the\n",
      "at\n",
      "her\n",
      "bed.\n",
      "Over\n",
      "the\n",
      "and\n",
      "is\n",
      "ports,\n",
      "two\n",
      "crap\n",
      "visuals\n",
      "own\n",
      "gave\n",
      "need\n",
      "can\n",
      "moment.\n",
      "This\n",
      "quite\n",
      "day\n",
      "the\n",
      "that\n",
      "municipal\n",
      "just\n",
      "from\n",
      "the\n",
      "or\n",
      "catch\n",
      "become\n",
      "government\n",
      "it\n",
      "maker\n",
      "that\n",
      "better\n",
      "be\n",
      "we've\n",
      "increased\n",
      "soon\n",
      "gone\n",
      "tin,\n",
      "live\n",
      "question\n",
      "would\n",
      "allpowerful\n",
      "profitable\n",
      "at\n",
      "chime\n",
      "to\n",
      "and\n",
      "on\n",
      "five\n",
      "that\n",
      "the\n",
      "more,\n",
      "didn't\n",
      "that\n",
      "following\n",
      "the\n",
      "to\n",
      "coast\n",
      "queen's\n",
      "and\n",
      "want\n",
      "candidates,\n",
      "not.\n",
      "Human\n",
      "been\n",
      "time\n",
      "the\n",
      "they\n",
      "for\n",
      "to\n",
      "in\n",
      "train\n",
      "origin\n",
      "entirely\n",
      "royal\n",
      "identification\n",
      "clue\n",
      "divine\n",
      "got\n",
      "frequency\n",
      "school,\n",
      "to\n",
      "that\n",
      "up\n",
      "attached\n",
      "into\n",
      "of\n",
      "a\n",
      "that\n",
      "and\n",
      "the\n",
      "answer\n",
      "reader\n",
      "inn,\n",
      "discipline's.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/EZCorp/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemma_words(row):\n",
    "    lemmatized_words = ''\n",
    "    for token in row.split(' '):\n",
    "        print(wordnet_lemmatizer.lemmatize(token))\n",
    "        lemmatized_words += wordnet_lemmatizer.lemmatize(token) + ' '\n",
    "    return lemmatized_words\n",
    "large_df['lemmatized_text'] = large_df.text.apply(lemma_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "# Or use the default model, which has fewer features:\n",
    "# nlp = spacy.load('en')\n",
    "# humanist_vols = pd.read_csv('web_scraped_humanist_listserv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"queen one cities packed destined design sighed n't term afloat know antiquity posterity probably ill plainly day arranged create use answer empty good scarfs examples would trial decided morals spare always worn small trumpet cache finds began mr sleepiness pros subdued joke chance incurred world rung brief top waved seriously enormity cache safe perceive cache military quite text become begin excessive desk multi feedback would influenced used opinion posts best rather get partially walls rational\",\n",
       " \"mellower experience continues essential tones rain expect one talk linux hesitated profitable noise target couple made ambushed better failures different best reported fie trust conflict- pouring room back without economics bed ports two crap visuals gave need moment quite day municipal catch become government makers better 've increased soon gone tin live question would allpowerful profitable chime five n't following coast queen 's want candidates human times train origin entirely royal identification clues divine got frequency school attached answer readers inn discipline 's\"]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_df.cleaned_text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_text = nlp(\"queen one cities packed destined design sighed n't term afloat know antiquity posterity probably ill plainly day arranged create use answer empty good scarfs examples would trial decided morals spare always worn small trumpet cache finds began mr sleepiness pros subdued joke chance incurred world rung brief top waved seriously enormity cache safe perceive cache military quite text become begin excessive desk multi feedback would influenced used opinion posts best rather get partially walls rational\")\n",
    "text2 = \"mellower experience continues essential\"\n",
    "spacy_text2 = nlp(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spacy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_text.similarity(spacy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "apples = nlp(\"I like apples\")\n",
    "oranges = nlp(\"I like oranges\")\n",
    "apples_oranges = apples.similarity(oranges)\n",
    "oranges_apples = oranges.similarity(apples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_word = spacy_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "apples, and_word, oranges = nlp(\"apples and oranges\")\n",
    "apples_oranges = apples.similarity(oranges)\n",
    "oranges_apples = oranges.similarity(apples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77809423"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oranges_apples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77809423"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apples_oranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "and_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen know 0.23805973\n",
      "queen antiquity 0.13954316\n",
      "queen posterity 0.0940259\n",
      "queen probably 0.23392698\n",
      "queen ill 0.24112208\n",
      "queen plainly 0.13126571\n",
      "queen day 0.22583804\n",
      "queen arranged 0.16365653\n",
      "queen create 0.12711608\n",
      "queen use 0.10462844\n",
      "one know 0.6638406\n",
      "one antiquity 0.15574029\n",
      "one posterity 0.21406326\n",
      "one probably 0.68213016\n",
      "one ill 0.4150426\n",
      "one plainly 0.33453116\n",
      "one day 0.5832917\n",
      "one arranged 0.3778583\n",
      "one create 0.47064194\n",
      "one use 0.5187773\n",
      "cities know 0.28537324\n",
      "cities antiquity 0.28732157\n",
      "cities posterity 0.10260976\n",
      "cities probably 0.3039254\n",
      "cities ill 0.16262354\n",
      "cities plainly 0.14544703\n",
      "cities day 0.28397027\n",
      "cities arranged 0.19345422\n",
      "cities create 0.28302506\n",
      "cities use 0.2254639\n",
      "packed know 0.24970748\n",
      "packed antiquity 0.058622047\n",
      "packed posterity 0.08346814\n",
      "packed probably 0.32096916\n",
      "packed ill 0.16002731\n",
      "packed plainly 0.17650807\n",
      "packed day 0.36919206\n",
      "packed arranged 0.35502332\n",
      "packed create 0.23777917\n",
      "packed use 0.21209633\n",
      "destined know 0.27380714\n",
      "destined antiquity 0.29518163\n",
      "destined posterity 0.36887106\n",
      "destined probably 0.40630385\n",
      "destined ill 0.30348867\n",
      "destined plainly 0.34389797\n",
      "destined day 0.23854597\n",
      "destined arranged 0.22488768\n",
      "destined create 0.29674226\n",
      "destined use 0.1775888\n",
      "design know 0.26582468\n",
      "design antiquity 0.08168121\n",
      "design posterity 0.011844215\n",
      "design probably 0.2191801\n",
      "design ill 0.068462275\n",
      "design plainly 0.11566456\n",
      "design day 0.21737087\n",
      "design arranged 0.1758647\n",
      "design create 0.5119139\n",
      "design use 0.37340862\n",
      "sighed know 0.21848272\n",
      "sighed antiquity 0.0486085\n",
      "sighed posterity 0.1657994\n",
      "sighed probably 0.20852262\n",
      "sighed ill 0.1508156\n",
      "sighed plainly 0.30335793\n",
      "sighed day 0.12938808\n",
      "sighed arranged 0.0709016\n",
      "sighed create -0.03458899\n",
      "sighed use -0.07883786\n",
      "n't know 0.8210698\n",
      "n't antiquity 0.042432304\n",
      "n't posterity 0.1289579\n",
      "n't probably 0.76827323\n",
      "n't ill 0.42242056\n",
      "n't plainly 0.31778246\n",
      "n't day 0.4549685\n",
      "n't arranged 0.16848019\n",
      "n't create 0.4327548\n",
      "n't use 0.5541814\n",
      "term know 0.34961873\n",
      "term antiquity 0.17208126\n",
      "term posterity 0.09599129\n",
      "term probably 0.428568\n",
      "term ill 0.2670891\n",
      "term plainly 0.26762614\n",
      "term day 0.3522414\n",
      "term arranged 0.19401869\n",
      "term create 0.2798067\n",
      "term use 0.43566605\n",
      "afloat know 0.17151754\n",
      "afloat antiquity 0.15499619\n",
      "afloat posterity 0.22717309\n",
      "afloat probably 0.2509159\n",
      "afloat ill 0.24373704\n",
      "afloat plainly 0.23418473\n",
      "afloat day 0.196111\n",
      "afloat arranged 0.15805565\n",
      "afloat create 0.17804475\n",
      "afloat use 0.06335418\n"
     ]
    }
   ],
   "source": [
    "for token1 in spacy_text[0:10]:\n",
    "    for token2 in spacy_text[10:20]:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">queen \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " cities packed destined design sighed n't term afloat know antiquity posterity probably ill plainly day arranged create use answer empty good scarfs examples would trial decided morals spare always worn small trumpet cache finds began mr sleepiness pros subdued joke chance incurred world rung brief top waved seriously enormity cache safe perceive cache military quite text become begin excessive desk multi feedback would influenced used opinion posts best rather get partially walls rational</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(spacy_text, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
